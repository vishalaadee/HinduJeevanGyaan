{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Update these paths as needed\n",
    "json_input_path = \"zer/analyzeDocResponse.json\"\n",
    "excel_output_path = \"zer/Extracted_Tables.xlsx\"\n",
    "\n",
    "# Load Textract JSON\n",
    "with open(json_input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    textract_data = json.load(f)\n",
    "\n",
    "# Build a block map for quick lookup\n",
    "blocks = textract_data[\"Blocks\"]\n",
    "block_map = {block[\"Id\"]: block for block in blocks}\n",
    "\n",
    "tables = []\n",
    "for block in blocks:\n",
    "    if block[\"BlockType\"] == \"TABLE\":\n",
    "        table_cells = []\n",
    "        for rel in block.get(\"Relationships\", []):\n",
    "            if rel[\"Type\"] == \"CHILD\":\n",
    "                for cell_id in rel[\"Ids\"]:\n",
    "                    cell = block_map[cell_id]\n",
    "                    if cell[\"BlockType\"] == \"CELL\":\n",
    "                        row = cell[\"RowIndex\"]\n",
    "                        col = cell[\"ColumnIndex\"]\n",
    "                        text = \"\"\n",
    "                        # Extract text within cell\n",
    "                        for child_rel in cell.get(\"Relationships\", []):\n",
    "                            if child_rel[\"Type\"] == \"CHILD\":\n",
    "                                for word_id in child_rel[\"Ids\"]:\n",
    "                                    word = block_map[word_id]\n",
    "                                    if word[\"BlockType\"] == \"WORD\":\n",
    "                                        text += word[\"Text\"] + \" \"\n",
    "                        table_cells.append({\n",
    "                            \"row\": row,\n",
    "                            \"col\": col,\n",
    "                            \"text\": text.strip()\n",
    "                        })\n",
    "        tables.append(table_cells)\n",
    "\n",
    "# Write tables to Excel\n",
    "writer = pd.ExcelWriter(excel_output_path, engine=\"xlsxwriter\")\n",
    "\n",
    "for idx, cells in enumerate(tables):\n",
    "    if not cells:\n",
    "        continue\n",
    "\n",
    "    max_row = max(cell[\"row\"] for cell in cells)\n",
    "    max_col = max(cell[\"col\"] for cell in cells)\n",
    "\n",
    "    # Initialize empty table\n",
    "    data = [[\"\" for _ in range(max_col)] for _ in range(max_row)]\n",
    "\n",
    "    # Fill the table with extracted text\n",
    "    for cell in cells:\n",
    "        data[cell[\"row\"] - 1][cell[\"col\"] - 1] = cell[\"text\"]\n",
    "\n",
    "    # Use first row as header if possible\n",
    "    if max_row > 1:\n",
    "        df = pd.DataFrame(data[1:], columns=data[0])\n",
    "    else:\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "    df.to_excel(writer, sheet_name=f\"Table_{idx + 1}\", index=False)\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print(f\"✅ Tables successfully written to: {excel_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== File: processing_engine.py =====\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import re\n",
    "import logging\n",
    "import io\n",
    "from PIL import Image, ImageEnhance\n",
    "from PyPDF2 import PdfReader\n",
    "from utils.loader import load_textract_json\n",
    "from utils.config import REGEX, SEGMENT_NAMES, FUZZY_REGEX, FUZZY_HEADERS\n",
    "from textracts.segment_extraction import extract_segment\n",
    "from preprocessing.extract_trade_data import extract_table_data\n",
    "from postprocessing.report_generator import generate_csv_reports\n",
    "from textracts.merge_pages import merge_textract_pages\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class TextractProcessor:\n",
    "\n",
    "    def __init__(self, pdf_file):\n",
    "        self.pdf_file_name = pdf_file\n",
    "        self.home_folder = os.getcwd()\n",
    "        self.pdf_path = os.path.join(self.home_folder, self.pdf_file_name)\n",
    "        self.output_folder = os.path.join(self.home_folder, \"pdf_pages\")\n",
    "        self.region_name = 'us-east-1'\n",
    "\n",
    "    def initialize_folder(self):\n",
    "        try:\n",
    "            if os.path.exists(self.output_folder):\n",
    "                shutil.rmtree(self.output_folder)\n",
    "            os.makedirs(self.output_folder)\n",
    "            logging.info(f\"Output folder initialized: {self.output_folder}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to initialize output folder: {e}\")\n",
    "            raise\n",
    "\n",
    "    def enhance_image(self, image):\n",
    "        try:\n",
    "            contrast_enhancer = ImageEnhance.Contrast(image)\n",
    "            image = contrast_enhancer.enhance(1.35)\n",
    "            return image\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to enhance image: {e}\")\n",
    "            raise\n",
    "\n",
    "    def extract_images_from_pdf(self):\n",
    "        try:\n",
    "            os.makedirs(self.output_folder, exist_ok=True)\n",
    "            reader = PdfReader(self.pdf_path)\n",
    "            enhanced_image_paths = []\n",
    "\n",
    "            for page_number, page in enumerate(reader.pages):\n",
    "                if \"/XObject\" in page.get(\"/Resources\", {}):\n",
    "                    xObject = page[\"/Resources\"][\"/XObject\"].get_object()\n",
    "                    for obj in xObject:\n",
    "                        if xObject[obj][\"/Subtype\"] == \"/Image\":\n",
    "                            size = (xObject[obj][\"/Width\"], xObject[obj][\"/Height\"])\n",
    "                            data = xObject[obj].get_data()\n",
    "                            filter_type = xObject[obj][\"/Filter\"]\n",
    "\n",
    "                            if filter_type == \"/DCTDecode\":\n",
    "                                image = Image.open(io.BytesIO(data))\n",
    "                            elif filter_type == \"/JPXDecode\":\n",
    "                                image = Image.open(io.BytesIO(data))\n",
    "                            elif filter_type == \"/FlateDecode\":\n",
    "                                mode = \"RGB\"\n",
    "                                image = Image.frombytes(mode, size, data)\n",
    "                            else:\n",
    "                                continue\n",
    "\n",
    "                            enhanced_image = self.enhance_image(image)\n",
    "                            image_path = os.path.join(self.output_folder, f\"page_{page_number+1}.png\")\n",
    "                            enhanced_image.save(image_path)\n",
    "                            enhanced_image_paths.append(image_path)\n",
    "\n",
    "            return enhanced_image_paths\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to extract images: {e}\")\n",
    "            raise\n",
    "\n",
    "    def analyze_images_with_textract(self, jpg_files):\n",
    "        import boto3\n",
    "        textract = boto3.client('textract', region_name=self.region_name)\n",
    "\n",
    "        responses = []\n",
    "        for jpg_file in jpg_files:\n",
    "            with open(jpg_file, 'rb') as img:\n",
    "                response = textract.analyze_document(\n",
    "                    Document={'Bytes': img.read()},\n",
    "                    FeatureTypes=['TABLES', 'FORMS', 'LAYOUT']\n",
    "                )\n",
    "                responses.append(response)\n",
    "        merged = {\"Blocks\": []}\n",
    "        for page in responses:\n",
    "            if \"Blocks\" in page:\n",
    "                merged[\"Blocks\"].extend(page[\"Blocks\"])\n",
    "        with open(\"textract_output.json\", \"w\") as f:\n",
    "            json.dump(merged, f, indent=4)\n",
    "\n",
    "        return merged\n",
    "\n",
    "    def process_textract_data(self, textract_data):\n",
    "        blocks = textract_data.get(\"Blocks\", [])\n",
    "        lines = [block['Text'] for block in blocks if block['BlockType'] == 'LINE']\n",
    "\n",
    "        demat = next((re.search(REGEX['demat_number'], line).group(0)\n",
    "                      for line in lines if re.search(REGEX['demat_number'], line)), \"NA\")\n",
    "\n",
    "        text_all = \" \".join(lines)\n",
    "        date_range_match = re.search(REGEX['date_range'], text_all)\n",
    "        date_range = date_range_match.group(1) if date_range_match else \"NA\"\n",
    "\n",
    "        segment_info = {\n",
    "            \"demat\": demat,\n",
    "            \"date_range\": date_range,\n",
    "            \"segments\": {},\n",
    "            \"metadata\": {},\n",
    "            \"missing_segments\": [],\n",
    "            \"empty_segments\": []\n",
    "        }\n",
    "\n",
    "        current_segment = None\n",
    "        skip_page = any(re.search(r\"holdings|positions\", block.get(\"Text\", \"\"), re.IGNORECASE)\n",
    "                        for block in blocks if block['BlockType'] == 'LINE')\n",
    "        if skip_page:\n",
    "            logging.info(\"Page skipped due to Holdings/Positions presence.\")\n",
    "            return []\n",
    "\n",
    "        for block in blocks:\n",
    "            if block['BlockType'] in [\"WORD\", \"LINE\"]:\n",
    "                text = block.get(\"Text\", \"\").lower()\n",
    "                for seg_name, pattern in SEGMENT_NAMES.items():\n",
    "                    if pattern.search(text):\n",
    "                        current_segment = seg_name\n",
    "            \n",
    "            if block['BlockType'] == 'TABLE' and current_segment:\n",
    "                partial_textract = {\"Blocks\": [block]}\n",
    "                trades = extract_table_data(partial_textract, current_segment)\n",
    "                \n",
    "                if current_segment not in segment_info['segments']:\n",
    "                    segment_info['segments'][current_segment] = {\"is_empty\": False, \"trades\": []}\n",
    "\n",
    "                segment_info['segments'][current_segment]['trades'].extend(trades)\n",
    "\n",
    "        found_segments = list(segment_info['segments'].keys())\n",
    "        segment_info['missing_segments'] = [s for s in SEGMENT_NAMES.keys() if s not in found_segments]\n",
    "\n",
    "        for seg in found_segments:\n",
    "            trades = segment_info['segments'][seg]['trades']\n",
    "            if not trades:\n",
    "                segment_info['segments'][seg]['is_empty'] = True\n",
    "                segment_info['empty_segments'].append(seg)\n",
    "            segment_info['metadata'][seg] = len(trades)\n",
    "\n",
    "        return [segment_info]\n",
    "\n",
    "    def main(self):\n",
    "        try:\n",
    "            logging.info(\"Initializing output folder...\")\n",
    "            self.initialize_folder()\n",
    "\n",
    "            logging.info(\"Extracting images from PDF...\")\n",
    "            jpg_files = self.extract_images_from_pdf()\n",
    "            if not jpg_files:\n",
    "                raise ValueError(\"No images generated from PDF.\")\n",
    "\n",
    "            logging.info(\"Analyzing images with Textract...\")\n",
    "            textract_responses = self.analyze_images_with_textract(jpg_files)\n",
    "\n",
    "            logging.info(\"Processing Textract data...\")\n",
    "            all_segment_info = self.process_textract_data(textract_responses)\n",
    "\n",
    "            if not all_segment_info:\n",
    "                logging.warning(\"PDF skipped, no valid segments processed.\")\n",
    "                return\n",
    "\n",
    "            logging.info(\"Generating final reports...\")\n",
    "            generate_csv_reports(all_segment_info)\n",
    "\n",
    "            logging.info(\"✅ Processing completed successfully.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Processing failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
